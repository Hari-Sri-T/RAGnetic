{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52fe2108",
   "metadata": {},
   "source": [
    "### Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b82100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n",
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n",
      "zsh:1: no matches found: sentence-transformers[torch]\n",
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n"
     ]
    }
   ],
   "source": [
    "# Use your environment manager; example with pip\n",
    "!pip install python-docx PyMuPDF mail-parser langchain faiss-cpu sentence-transformers rank_bm25\n",
    "!pip install transformers accelerate\n",
    "!pip install sentence-transformers[torch]  # if needed\n",
    "!pip install cross-encoder  # or use sentence-transformers CrossEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f30f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi[all] in ./.venv/lib/python3.10/site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in ./.venv/lib/python3.10/site-packages (0.35.0)\n",
      "Requirement already satisfied: python-multipart in ./.venv/lib/python3.10/site-packages (0.0.20)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (2.32.4)\n",
      "Requirement already satisfied: chromadb in ./.venv/lib/python3.10/site-packages (1.0.16)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (2.11.7)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (0.47.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (4.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (6.0.2)\n",
      "Requirement already satisfied: fastapi-cli[standard]>=0.0.8 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (0.0.8)\n",
      "Requirement already satisfied: httpx>=0.23.0 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.1.5 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=1.1.0 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (2.2.0)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (5.10.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.0.0 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (2.10.1)\n",
      "Requirement already satisfied: pydantic-extra-types>=2.0.0 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (2.10.5)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (2.2.0)\n",
      "Requirement already satisfied: orjson>=3.2.1 in ./.venv/lib/python3.10/site-packages (from fastapi[all]) (3.11.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.10/site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.10/site-packages (from uvicorn) (8.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.10/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./.venv/lib/python3.10/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (4.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.10/site-packages (from chromadb) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./.venv/lib/python3.10/site-packages (from chromadb) (2.2.6)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.10/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.10/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: packaging>=19.1 in ./.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in ./.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./.venv/lib/python3.10/site-packages (from email-validator>=2.0.0->fastapi[all]) (2.7.0)\n",
      "Requirement already satisfied: rich-toolkit>=0.14.8 in ./.venv/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.8->fastapi[all]) (0.14.9)\n",
      "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in ./.venv/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.8->fastapi[all]) (0.1.5)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[all]) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[all]) (1.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2>=3.1.5->fastapi[all]) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (6.31.1)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./.venv/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (2.33.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.10/site-packages (from pydantic-settings>=2.0.0->fastapi[all]) (1.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.34.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.10/site-packages (from uvicorn) (15.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.10/site-packages (from uvicorn) (1.1.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.10/site-packages (from uvicorn) (0.6.4)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./.venv/lib/python3.10/site-packages (from uvicorn) (0.21.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->fastapi[all]) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->fastapi[all]) (1.3.1)\n",
      "Requirement already satisfied: sentry-sdk>=2.20.0 in ./.venv/lib/python3.10/site-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8->fastapi[all]) (2.34.1)\n",
      "Requirement already satisfied: rignore>=0.5.1 in ./.venv/lib/python3.10/site-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8->fastapi[all]) (0.6.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.7.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.7)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"fastapi[all]\" uvicorn python-multipart requests chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60c66993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n",
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n"
     ]
    }
   ],
   "source": [
    "# Use your environment manager; example with pip\n",
    "!pip install python-docx PyMuPDF mail-parser sentence-transformers 'faiss-cpu' rank_bm25\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "251ac738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f85fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n"
     ]
    }
   ],
   "source": [
    "!pip install mail-parser  # if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3eb1b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hari/Professional/Projects/Advanced RAG Pipeline testing on pi3 and nous hermes/.venv/bin/pip: 2: exec: /home/hari/Professional/Projects/Bajaj HackrX 6 /.venv/bin/python3: not found\n"
     ]
    }
   ],
   "source": [
    "!pip install cross-encoder  # or use sentence-transformers CrossEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e4350",
   "metadata": {},
   "source": [
    "### Document Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "050a3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf  # PyMuPDF\n",
    "import docx\n",
    "import mailparser\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "def extract_pdf_with_structure(pdf_path: str) -> List[Dict]:\n",
    "    \"\"\"Returns list of {'text': str, 'page': int, 'block': int, 'heading': str or None}\"\"\"\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    results = []\n",
    "    for pageno in range(doc.page_count):\n",
    "        page = doc.load_page(pageno)\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b_idx, block in enumerate(blocks):\n",
    "            # block may contain lines; join them\n",
    "            lines = []\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line.get(\"spans\", []):\n",
    "                    lines.append(span.get(\"text\", \"\"))\n",
    "            text = \" \".join(lines).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            # Simple heuristic detect heading (all caps or ends with ':')\n",
    "            heading = None\n",
    "            if len(text) < 120 and (text.isupper() or text.endswith(\":\")):\n",
    "                heading = text\n",
    "            results.append({\"text\": text, \"page\": pageno+1, \"block\": b_idx, \"heading\": heading})\n",
    "    return results\n",
    "\n",
    "def extract_docx_with_structure(docx_path: str):\n",
    "    doc = docx.Document(docx_path)\n",
    "    results = []\n",
    "    for i, para in enumerate(doc.paragraphs):\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        # heading detection via style or bold\n",
    "        style = para.style.name.lower() if para.style else \"\"\n",
    "        heading = text if \"heading\" in style else None\n",
    "        results.append({\"text\": text, \"para_idx\": i, \"heading\": heading})\n",
    "    return results\n",
    "\n",
    "def extract_email(msg_path: str):\n",
    "    m = mailparser.parse_from_file(msg_path)\n",
    "    body = m.body or \"\"\n",
    "    # optionally parse attachments separately\n",
    "    return [{\"text\": body, \"from\": m.from_, \"to\": m.to, \"subject\": m.subject}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d99b8fb",
   "metadata": {},
   "source": [
    "### Clause Aware Sematic Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae0d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "CLAUSE_RE = re.compile(r'^\\s*\\d+(\\.\\d+){0,}\\s+')  # detects \"1.\", \"2.1\", etc.\n",
    "\n",
    "def semantic_chunker(structured_parts, max_tokens=350, overlap_tokens=50):\n",
    "    \"\"\"\n",
    "    structured_parts: list of dicts from extract_pdf_with_structure\n",
    "    returns list of chunks: dicts {text, metadata}\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    buffer = \"\"\n",
    "    buffer_meta = {\"pages\": set(), \"headings\": [], \"source_blocks\": []}\n",
    "\n",
    "    def flush_buffer():\n",
    "        nonlocal buffer, buffer_meta\n",
    "        if not buffer.strip(): \n",
    "            return\n",
    "        chunks.append({\n",
    "            \"text\": buffer.strip(),\n",
    "            \"pages\": sorted(buffer_meta[\"pages\"]),\n",
    "            \"headings\": buffer_meta[\"headings\"],\n",
    "            \"sources\": buffer_meta[\"source_blocks\"]\n",
    "        })\n",
    "        # set overlap: keep last `overlap_tokens` tokens as new buffer\n",
    "        toks = tokenizer.encode(buffer)\n",
    "        overlap_toks = toks[-overlap_tokens:] if len(toks) > overlap_tokens else toks\n",
    "        buffer = tokenizer.decode(overlap_toks) if overlap_toks else \"\"\n",
    "        buffer_meta = {\"pages\": set(), \"headings\": [], \"source_blocks\": []}\n",
    "\n",
    "    for part in structured_parts:\n",
    "        text = part[\"text\"]\n",
    "        # if heading or clause start: prefer flush (start new chunk)\n",
    "        if part.get(\"heading\") or CLAUSE_RE.match(text):\n",
    "            # flush current chunk if not empty\n",
    "            if buffer.strip():\n",
    "                flush_buffer()\n",
    "            # start new chunk with the heading/clause\n",
    "            buffer += (text + \"\\n\")\n",
    "            buffer_meta[\"pages\"].add(part.get(\"page\", part.get(\"para_idx\", 0)))\n",
    "            buffer_meta[\"headings\"].append(part.get(\"heading\") or \"\")\n",
    "            buffer_meta[\"source_blocks\"].append((part.get(\"page\",0), part.get(\"block\",0)))\n",
    "            # if this too large, flush\n",
    "            if len(tokenizer.encode(buffer)) > max_tokens:\n",
    "                flush_buffer()\n",
    "            continue\n",
    "\n",
    "        # otherwise append\n",
    "        buffer += (\" \" + text)\n",
    "        buffer_meta[\"pages\"].add(part.get(\"page\", part.get(\"para_idx\", 0)))\n",
    "        buffer_meta[\"source_blocks\"].append((part.get(\"page\",0), part.get(\"block\",0)))\n",
    "        if len(tokenizer.encode(buffer)) > max_tokens:\n",
    "            flush_buffer()\n",
    "\n",
    "    if buffer.strip():\n",
    "        flush_buffer()\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132c705",
   "metadata": {},
   "source": [
    "### D — Embeddings: high-quality & normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83fcc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "def embed_texts(texts: List[str]):\n",
    "    embs = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "    # L2-normalize for cosine in FAISS\n",
    "    norms = np.linalg.norm(embs, axis=1, keepdims=True)\n",
    "    norms[norms==0] = 1.0\n",
    "    embs = embs / norms\n",
    "    return embs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e6b51",
   "metadata": {},
   "source": [
    "### E — Vector DB (FAISS) with metadata mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f01374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import json\n",
    "\n",
    "def build_faiss_index(embs: np.ndarray, ids: List[int], ef_construction=200, M=64):\n",
    "    d = embs.shape[1]\n",
    "    # HNSW index\n",
    "    index = faiss.IndexHNSWFlat(d, M)\n",
    "    index.hnsw.efConstruction = ef_construction\n",
    "    # wrap in ID map so we can assign stable ids\n",
    "    id_index = faiss.IndexIDMap(index)\n",
    "    id_index.add_with_ids(embs, np.array(ids, dtype='int64'))\n",
    "    return id_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6185fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 111 chunks.\n"
     ]
    }
   ],
   "source": [
    "# 1. Ingest a document to get structured parts\n",
    "# Make sure you have a file named 'policy.pdf' or change the name\n",
    "structured = extract_pdf_with_structure(\"policy.pdf\") \n",
    "\n",
    "# 2. Run the semantic chunker to create the 'chunks' variable\n",
    "chunks = semantic_chunker(structured)\n",
    "\n",
    "# NOW you can run the code that uses the 'chunks' variable\n",
    "print(f\"Successfully created {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b39b2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata store\n",
    "metadata_store = {}  # id -> {text, pages, headings, source}\n",
    "# when constructing:\n",
    "for i, chunk in enumerate(chunks):\n",
    "    id_ = i+1\n",
    "    metadata_store[id_] = chunk\n",
    "# save metadata_store to disk\n",
    "with open(\"meta.json\", \"w\") as f:\n",
    "    json.dump(metadata_store, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02d03c",
   "metadata": {},
   "source": [
    "### F — Hybrid retrieval: BM25 + Embeddings + union + rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cf250",
   "metadata": {},
   "source": [
    "#### 1) BM25 (exact-match for clauses & numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71d5df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "tokenized_corpus = [tokenizer.tokenize(c['text']) for c in chunks]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def bm25_search(query, top_k=10):\n",
    "    tokenized_q = tokenizer.tokenize(query)\n",
    "    scores = bm25.get_scores(tokenized_q)\n",
    "    top_idxs = np.argsort(scores)[::-1][:top_k]\n",
    "    return list(top_idxs), scores[top_idxs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffee1a4",
   "metadata": {},
   "source": [
    "#### 2) Embedding search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddbe5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_search(query, faiss_index, top_k=10):\n",
    "    q_emb = embed_texts([query])  # normalized\n",
    "    D, I = faiss_index.search(q_emb.astype('float32'), top_k)\n",
    "    return I[0].tolist(), D[0].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd9577",
   "metadata": {},
   "source": [
    "### 3) Combine results and rerank using CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcb8b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")  # good speed/quality\n",
    "\n",
    "def hybrid_retrieve(query, top_k=8):\n",
    "    # Retrieve a smaller number of initial candidates, e.g., 15 from each search\n",
    "    bm25_ids, _ = bm25_search(query, top_k=15)\n",
    "    emb_ids, _ = embed_search(query, faiss_index, top_k=15)\n",
    "\n",
    "    # Combine and deduplicate the candidates\n",
    "    candidate_ids = list(dict.fromkeys(bm25_ids + emb_ids)) \n",
    "    candidate_texts = [metadata_store[int(cid)+1]['text'] for cid in candidate_ids]\n",
    "\n",
    "    # The reranker now has fewer documents to process\n",
    "    pairs = [(query, t) for t in candidate_texts]\n",
    "    scores = reranker.predict(pairs)\n",
    "    \n",
    "    ranked = sorted(zip(candidate_ids, candidate_texts, scores), key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Return the final top_k results after reranking\n",
    "    top_ranked = ranked[:top_k] \n",
    "    return top_ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0ee84",
   "metadata": {},
   "source": [
    "### Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d126539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, top_chunks, llm_call_fn):\n",
    "    \"\"\"\n",
    "    top_chunks: list of tuples (id, text, rerank_score)\n",
    "    llm_call_fn: function that accepts prompt and returns answer & score\n",
    "    \"\"\"\n",
    "    # build prompt with sources and instructions\n",
    "    sources_text = \"\\n\\n\".join([f\"[Source {i+1} | id={cid} | score={round(s,3)}]\\n{txt}\" \n",
    "                                for i, (cid, txt, s) in enumerate(top_chunks)])\n",
    "    prompt = f\"\"\"\n",
    "You are a policy/contract assistant. Use ONLY the information in the provided sources to answer the query.\n",
    "If answer is not in sources, say \"Not found in documents\".\n",
    "Provide:\n",
    "1) Short answer (1-3 sentences)\n",
    "2) Supporting quotes with source ids and pages\n",
    "3) Explanation of why these sources match (2-3 lines)\n",
    "4) Confidence (0-1)\n",
    "\n",
    "SOURCES:\n",
    "{sources_text}\n",
    "\n",
    "QUERY: {query}\n",
    "\n",
    "Answer in JSON only with keys: answer, evidence, explanation, confidence\n",
    "\"\"\"\n",
    "    response = llm_call_fn(prompt)  # implement with OpenAI/LLM of choice\n",
    "    # parse response if LLM already returns JSON, else parse\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b530924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "# Use the Nous-Hermes 2 model you have already downloaded\n",
    "OLLAMA_MODEL = 'nous-hermes2' \n",
    "\n",
    "def llm_call_fn(prompt: str):\n",
    "    \"\"\"\n",
    "    Function that accepts a prompt and returns a structured answer from a local Ollama model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The 'format=\"json\"' argument tells Ollama to guarantee the output is valid JSON.\n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL,\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            format='json'\n",
    "        )\n",
    "        \n",
    "        # The response content should be a JSON string, so we parse it into a dict\n",
    "        response_content = response['message']['content']\n",
    "        return json.loads(response_content)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle potential errors (e.g., model not running, JSON parsing failed)\n",
    "        print(f\"Error during LLM call: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"Error generating response from the model.\",\n",
    "            \"evidence\": [],\n",
    "            \"explanation\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8d3de",
   "metadata": {},
   "source": [
    "# Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "640e7824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67ee2a366d24de0956f9b86d25af086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd37ac43fcb44a7b9c0b455689572ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Yes', 'evidence': 'Source 1 - Page 9, Section 3.2.1', 'explanation': 'According to Source 1 on page 9 under section 3.2.1, a No Claim Discount (NCD) of flat 5% is allowed on the *base premium for renewal policies with a term of one year, provided claims are not reported in the expiring Policy.', 'confidence': 1}\n"
     ]
    }
   ],
   "source": [
    "# 1. Ingest -> structured_parts\n",
    "structured = extract_pdf_with_structure(\"policy.pdf\")    # or docx/email functions\n",
    "\n",
    "# 2. Chunk\n",
    "chunks = semantic_chunker(structured)\n",
    "\n",
    "# 3. Embed and build FAISS\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "embs = embed_texts(texts).astype('float32')\n",
    "ids = list(range(1, len(texts)+1))\n",
    "faiss_index = build_faiss_index(embs, ids)\n",
    "# store metadata_store as id->chunk\n",
    "\n",
    "# 4. Build BM25\n",
    "tokenized_corpus = [tokenizer.tokenize(t) for t in texts]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# 5. Query -> hybrid_retrieve -> top_chunks\n",
    "top_chunks = hybrid_retrieve(\"A No Claim Discount of 5% on the base premium is offered on renewal for a one-year policy term if no claims were made in the preceding year. The maximum aggregate NCD is capped at 5% of the total base premium\", top_k=5)\n",
    "print\n",
    "# 6. Generate answer\n",
    "resp_json = generate_answer(\"A No Claim Discount of 5% on the base premium is offered on renewal for a one-year policy term if no claims were made in the preceding year. The maximum aggregate NCD is capped at 5% of the total base premium\", top_chunks, llm_call_fn)\n",
    "\n",
    "print(resp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70f655d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "# Let's assume you are running Phi-3 Mini locally via 'ollama run phi-3:mini'\n",
    "OLLAMA_MODEL = 'phi3' \n",
    "\n",
    "def llm_call_fn(prompt: str):\n",
    "    \"\"\"\n",
    "    Function that accepts a prompt and returns a structured answer from a local Ollama model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The 'format=\"json\"' argument tells Ollama to guarantee the output is valid JSON\n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL,\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            format='json'\n",
    "        )\n",
    "        \n",
    "        # The response content should be a JSON string, so we parse it into a dict\n",
    "        response_content = response['message']['content']\n",
    "        return json.loads(response_content)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle potential errors (e.g., model not running, JSON parsing failed)\n",
    "        print(f\"Error during LLM call: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"Error generating response from the model.\",\n",
    "            \"evidence\": [],\n",
    "            \"explanation\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06aec870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d6499ef9b244a8a290a689f7cbcd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0db5f216324dd3b89f2a89d40cdf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Not found in documents', 'evidence': None, 'explanation': 'The provided sources do not contain specific information about a No Claim Discount (NCD) of flat 5% on the base premium for one-year policy terms with no claims made during that year. The documents discuss NCDs but without specifying whether it is just applicable to annual renewals or also at other periods, such as upon first issuance.', 'confidence': 0}\n"
     ]
    }
   ],
   "source": [
    "# 1. Ingest -> structured_parts\n",
    "structured = extract_pdf_with_structure(\"policy.pdf\")    # or docx/email functions\n",
    "\n",
    "# 2. Chunk\n",
    "chunks = semantic_chunker(structured)\n",
    "\n",
    "# 3. Embed and build FAISS\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "embs = embed_texts(texts).astype('float32')\n",
    "ids = list(range(1, len(texts)+1))\n",
    "faiss_index = build_faiss_index(embs, ids)\n",
    "# store metadata_store as id->chunk\n",
    "\n",
    "# 4. Build BM25\n",
    "tokenized_corpus = [tokenizer.tokenize(t) for t in texts]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# 5. Query -> hybrid_retrieve -> top_chunks\n",
    "top_chunks = hybrid_retrieve(\"A No Claim Discount of 5% on the base premium is offered on renewal for a one-year policy term if no claims were made in the preceding year. The maximum aggregate NCD is capped at 5% of the total base premium\", top_k=5)\n",
    "print\n",
    "# 6. Generate answer\n",
    "resp_json = generate_answer(\"A No Claim Discount of 5% on the base premium is offered on renewal for a one-year policy term if no claims were made in the preceding year. The maximum aggregate NCD is capped at 5% of the total base premium\", top_chunks, llm_call_fn)\n",
    "\n",
    "print(resp_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf6ebb",
   "metadata": {},
   "source": [
    "##### Generally phi3 is faster and the outputs seemed similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
